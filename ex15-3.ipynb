{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15.3 지도학습 모델의 종류\n",
    "## 결정트리\n",
    "### 데이터 분석 및 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "[5.1 3.5 1.4 0.2]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#p254\n",
    "from sklearn.datasets import load_iris  # iris 데이터 세트 가져오기\n",
    "iris = load_iris()                      # iris 토이 데이터세트를 iris 변수에 저장\n",
    "print(iris.feature_names)               # 특징(feature)들을 출력\n",
    "print(iris.target_names)                # 학습 라벨에 해당하는 target을 출력\n",
    "print(iris.data[0])                     # 첫 번째 데이터에 저장된 feature값 출력\n",
    "print(iris.target[0])                   # 첫 번째 데이터에 저장된 target값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0: label 0, features [5.1 3.5 1.4 0.2]\n",
      "Example 1: label 0, features [4.9 3.  1.4 0.2]\n",
      "Example 2: label 0, features [4.7 3.2 1.3 0.2]\n",
      "Example 3: label 0, features [4.6 3.1 1.5 0.2]\n",
      "Example 4: label 0, features [5.  3.6 1.4 0.2]\n",
      "Example 5: label 0, features [5.4 3.9 1.7 0.4]\n",
      "Example 6: label 0, features [4.6 3.4 1.4 0.3]\n",
      "Example 7: label 0, features [5.  3.4 1.5 0.2]\n",
      "Example 8: label 0, features [4.4 2.9 1.4 0.2]\n",
      "Example 9: label 0, features [4.9 3.1 1.5 0.1]\n",
      "Example 10: label 0, features [5.4 3.7 1.5 0.2]\n",
      "Example 11: label 0, features [4.8 3.4 1.6 0.2]\n",
      "Example 12: label 0, features [4.8 3.  1.4 0.1]\n",
      "Example 13: label 0, features [4.3 3.  1.1 0.1]\n",
      "Example 14: label 0, features [5.8 4.  1.2 0.2]\n",
      "Example 15: label 0, features [5.7 4.4 1.5 0.4]\n",
      "Example 16: label 0, features [5.4 3.9 1.3 0.4]\n",
      "Example 17: label 0, features [5.1 3.5 1.4 0.3]\n",
      "Example 18: label 0, features [5.7 3.8 1.7 0.3]\n",
      "Example 19: label 0, features [5.1 3.8 1.5 0.3]\n",
      "Example 20: label 0, features [5.4 3.4 1.7 0.2]\n",
      "Example 21: label 0, features [5.1 3.7 1.5 0.4]\n",
      "Example 22: label 0, features [4.6 3.6 1.  0.2]\n",
      "Example 23: label 0, features [5.1 3.3 1.7 0.5]\n",
      "Example 24: label 0, features [4.8 3.4 1.9 0.2]\n",
      "Example 25: label 0, features [5.  3.  1.6 0.2]\n",
      "Example 26: label 0, features [5.  3.4 1.6 0.4]\n",
      "Example 27: label 0, features [5.2 3.5 1.5 0.2]\n",
      "Example 28: label 0, features [5.2 3.4 1.4 0.2]\n",
      "Example 29: label 0, features [4.7 3.2 1.6 0.2]\n",
      "Example 30: label 0, features [4.8 3.1 1.6 0.2]\n",
      "Example 31: label 0, features [5.4 3.4 1.5 0.4]\n",
      "Example 32: label 0, features [5.2 4.1 1.5 0.1]\n",
      "Example 33: label 0, features [5.5 4.2 1.4 0.2]\n",
      "Example 34: label 0, features [4.9 3.1 1.5 0.2]\n",
      "Example 35: label 0, features [5.  3.2 1.2 0.2]\n",
      "Example 36: label 0, features [5.5 3.5 1.3 0.2]\n",
      "Example 37: label 0, features [4.9 3.6 1.4 0.1]\n",
      "Example 38: label 0, features [4.4 3.  1.3 0.2]\n",
      "Example 39: label 0, features [5.1 3.4 1.5 0.2]\n",
      "Example 40: label 0, features [5.  3.5 1.3 0.3]\n",
      "Example 41: label 0, features [4.5 2.3 1.3 0.3]\n",
      "Example 42: label 0, features [4.4 3.2 1.3 0.2]\n",
      "Example 43: label 0, features [5.  3.5 1.6 0.6]\n",
      "Example 44: label 0, features [5.1 3.8 1.9 0.4]\n",
      "Example 45: label 0, features [4.8 3.  1.4 0.3]\n",
      "Example 46: label 0, features [5.1 3.8 1.6 0.2]\n",
      "Example 47: label 0, features [4.6 3.2 1.4 0.2]\n",
      "Example 48: label 0, features [5.3 3.7 1.5 0.2]\n",
      "Example 49: label 0, features [5.  3.3 1.4 0.2]\n",
      "Example 50: label 1, features [7.  3.2 4.7 1.4]\n",
      "Example 51: label 1, features [6.4 3.2 4.5 1.5]\n",
      "Example 52: label 1, features [6.9 3.1 4.9 1.5]\n",
      "Example 53: label 1, features [5.5 2.3 4.  1.3]\n",
      "Example 54: label 1, features [6.5 2.8 4.6 1.5]\n",
      "Example 55: label 1, features [5.7 2.8 4.5 1.3]\n",
      "Example 56: label 1, features [6.3 3.3 4.7 1.6]\n",
      "Example 57: label 1, features [4.9 2.4 3.3 1. ]\n",
      "Example 58: label 1, features [6.6 2.9 4.6 1.3]\n",
      "Example 59: label 1, features [5.2 2.7 3.9 1.4]\n",
      "Example 60: label 1, features [5.  2.  3.5 1. ]\n",
      "Example 61: label 1, features [5.9 3.  4.2 1.5]\n",
      "Example 62: label 1, features [6.  2.2 4.  1. ]\n",
      "Example 63: label 1, features [6.1 2.9 4.7 1.4]\n",
      "Example 64: label 1, features [5.6 2.9 3.6 1.3]\n",
      "Example 65: label 1, features [6.7 3.1 4.4 1.4]\n",
      "Example 66: label 1, features [5.6 3.  4.5 1.5]\n",
      "Example 67: label 1, features [5.8 2.7 4.1 1. ]\n",
      "Example 68: label 1, features [6.2 2.2 4.5 1.5]\n",
      "Example 69: label 1, features [5.6 2.5 3.9 1.1]\n",
      "Example 70: label 1, features [5.9 3.2 4.8 1.8]\n",
      "Example 71: label 1, features [6.1 2.8 4.  1.3]\n",
      "Example 72: label 1, features [6.3 2.5 4.9 1.5]\n",
      "Example 73: label 1, features [6.1 2.8 4.7 1.2]\n",
      "Example 74: label 1, features [6.4 2.9 4.3 1.3]\n",
      "Example 75: label 1, features [6.6 3.  4.4 1.4]\n",
      "Example 76: label 1, features [6.8 2.8 4.8 1.4]\n",
      "Example 77: label 1, features [6.7 3.  5.  1.7]\n",
      "Example 78: label 1, features [6.  2.9 4.5 1.5]\n",
      "Example 79: label 1, features [5.7 2.6 3.5 1. ]\n",
      "Example 80: label 1, features [5.5 2.4 3.8 1.1]\n",
      "Example 81: label 1, features [5.5 2.4 3.7 1. ]\n",
      "Example 82: label 1, features [5.8 2.7 3.9 1.2]\n",
      "Example 83: label 1, features [6.  2.7 5.1 1.6]\n",
      "Example 84: label 1, features [5.4 3.  4.5 1.5]\n",
      "Example 85: label 1, features [6.  3.4 4.5 1.6]\n",
      "Example 86: label 1, features [6.7 3.1 4.7 1.5]\n",
      "Example 87: label 1, features [6.3 2.3 4.4 1.3]\n",
      "Example 88: label 1, features [5.6 3.  4.1 1.3]\n",
      "Example 89: label 1, features [5.5 2.5 4.  1.3]\n",
      "Example 90: label 1, features [5.5 2.6 4.4 1.2]\n",
      "Example 91: label 1, features [6.1 3.  4.6 1.4]\n",
      "Example 92: label 1, features [5.8 2.6 4.  1.2]\n",
      "Example 93: label 1, features [5.  2.3 3.3 1. ]\n",
      "Example 94: label 1, features [5.6 2.7 4.2 1.3]\n",
      "Example 95: label 1, features [5.7 3.  4.2 1.2]\n",
      "Example 96: label 1, features [5.7 2.9 4.2 1.3]\n",
      "Example 97: label 1, features [6.2 2.9 4.3 1.3]\n",
      "Example 98: label 1, features [5.1 2.5 3.  1.1]\n",
      "Example 99: label 1, features [5.7 2.8 4.1 1.3]\n",
      "Example 100: label 2, features [6.3 3.3 6.  2.5]\n",
      "Example 101: label 2, features [5.8 2.7 5.1 1.9]\n",
      "Example 102: label 2, features [7.1 3.  5.9 2.1]\n",
      "Example 103: label 2, features [6.3 2.9 5.6 1.8]\n",
      "Example 104: label 2, features [6.5 3.  5.8 2.2]\n",
      "Example 105: label 2, features [7.6 3.  6.6 2.1]\n",
      "Example 106: label 2, features [4.9 2.5 4.5 1.7]\n",
      "Example 107: label 2, features [7.3 2.9 6.3 1.8]\n",
      "Example 108: label 2, features [6.7 2.5 5.8 1.8]\n",
      "Example 109: label 2, features [7.2 3.6 6.1 2.5]\n",
      "Example 110: label 2, features [6.5 3.2 5.1 2. ]\n",
      "Example 111: label 2, features [6.4 2.7 5.3 1.9]\n",
      "Example 112: label 2, features [6.8 3.  5.5 2.1]\n",
      "Example 113: label 2, features [5.7 2.5 5.  2. ]\n",
      "Example 114: label 2, features [5.8 2.8 5.1 2.4]\n",
      "Example 115: label 2, features [6.4 3.2 5.3 2.3]\n",
      "Example 116: label 2, features [6.5 3.  5.5 1.8]\n",
      "Example 117: label 2, features [7.7 3.8 6.7 2.2]\n",
      "Example 118: label 2, features [7.7 2.6 6.9 2.3]\n",
      "Example 119: label 2, features [6.  2.2 5.  1.5]\n",
      "Example 120: label 2, features [6.9 3.2 5.7 2.3]\n",
      "Example 121: label 2, features [5.6 2.8 4.9 2. ]\n",
      "Example 122: label 2, features [7.7 2.8 6.7 2. ]\n",
      "Example 123: label 2, features [6.3 2.7 4.9 1.8]\n",
      "Example 124: label 2, features [6.7 3.3 5.7 2.1]\n",
      "Example 125: label 2, features [7.2 3.2 6.  1.8]\n",
      "Example 126: label 2, features [6.2 2.8 4.8 1.8]\n",
      "Example 127: label 2, features [6.1 3.  4.9 1.8]\n",
      "Example 128: label 2, features [6.4 2.8 5.6 2.1]\n",
      "Example 129: label 2, features [7.2 3.  5.8 1.6]\n",
      "Example 130: label 2, features [7.4 2.8 6.1 1.9]\n",
      "Example 131: label 2, features [7.9 3.8 6.4 2. ]\n",
      "Example 132: label 2, features [6.4 2.8 5.6 2.2]\n",
      "Example 133: label 2, features [6.3 2.8 5.1 1.5]\n",
      "Example 134: label 2, features [6.1 2.6 5.6 1.4]\n",
      "Example 135: label 2, features [7.7 3.  6.1 2.3]\n",
      "Example 136: label 2, features [6.3 3.4 5.6 2.4]\n",
      "Example 137: label 2, features [6.4 3.1 5.5 1.8]\n",
      "Example 138: label 2, features [6.  3.  4.8 1.8]\n",
      "Example 139: label 2, features [6.9 3.1 5.4 2.1]\n",
      "Example 140: label 2, features [6.7 3.1 5.6 2.4]\n",
      "Example 141: label 2, features [6.9 3.1 5.1 2.3]\n",
      "Example 142: label 2, features [5.8 2.7 5.1 1.9]\n",
      "Example 143: label 2, features [6.8 3.2 5.9 2.3]\n",
      "Example 144: label 2, features [6.7 3.3 5.7 2.5]\n",
      "Example 145: label 2, features [6.7 3.  5.2 2.3]\n",
      "Example 146: label 2, features [6.3 2.5 5.  1.9]\n",
      "Example 147: label 2, features [6.5 3.  5.2 2. ]\n",
      "Example 148: label 2, features [6.2 3.4 5.4 2.3]\n",
      "Example 149: label 2, features [5.9 3.  5.1 1.8]\n"
     ]
    }
   ],
   "source": [
    "#p255\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "for i in range(len(iris.target)):\n",
    "    print(\"Example %d: label %s, features %s\" % (i, iris.target[i], iris.data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "iris = load_iris()\n",
    "test = [0,50,100]\n",
    "\n",
    "# training data 준비과정!\n",
    "train_data = np.delete(iris.data, test, axis=0)   # 세 개의 데이터들을 데이터변수에서 제거\n",
    "train_target = np.delete(iris.target, test)       # 세 개의 데이터들을 타깃변수에서 제거\n",
    "\n",
    "# testing data 준비과정!\n",
    "test_data = iris.data[test]\n",
    "test_target = iris.target[test]\n",
    "\n",
    "# 결정트리 생성!\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(train_data, train_target)\n",
    "\n",
    "# 출력\n",
    "print(test_target)\n",
    "print(clf.predict(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "#p257\n",
    "a = np.array([[1,2], [3,4]])\n",
    "print(a.flatten())                     # 또는 print(a.flatten('C'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 2 4]\n"
     ]
    }
   ],
   "source": [
    "print(a.flatten('F'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147, 4)\n",
      "[[4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "iris = load_iris()\n",
    "test_idx = [0,50,100]\n",
    "train_data = np.delete(iris.data, test_idx, axis=0)\n",
    "print(train_data.shape)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 3)\n",
      "[[3.5 1.4 0.2]\n",
      " [3.  1.4 0.2]\n",
      " [3.2 1.3 0.2]\n",
      " [3.1 1.5 0.2]\n",
      " [3.6 1.4 0.2]\n",
      " [3.9 1.7 0.4]\n",
      " [3.4 1.4 0.3]\n",
      " [3.4 1.5 0.2]\n",
      " [2.9 1.4 0.2]\n",
      " [3.1 1.5 0.1]\n",
      " [3.7 1.5 0.2]\n",
      " [3.4 1.6 0.2]\n",
      " [3.  1.4 0.1]\n",
      " [3.  1.1 0.1]\n",
      " [4.  1.2 0.2]\n",
      " [4.4 1.5 0.4]\n",
      " [3.9 1.3 0.4]\n",
      " [3.5 1.4 0.3]\n",
      " [3.8 1.7 0.3]\n",
      " [3.8 1.5 0.3]\n",
      " [3.4 1.7 0.2]\n",
      " [3.7 1.5 0.4]\n",
      " [3.6 1.  0.2]\n",
      " [3.3 1.7 0.5]\n",
      " [3.4 1.9 0.2]\n",
      " [3.  1.6 0.2]\n",
      " [3.4 1.6 0.4]\n",
      " [3.5 1.5 0.2]\n",
      " [3.4 1.4 0.2]\n",
      " [3.2 1.6 0.2]\n",
      " [3.1 1.6 0.2]\n",
      " [3.4 1.5 0.4]\n",
      " [4.1 1.5 0.1]\n",
      " [4.2 1.4 0.2]\n",
      " [3.1 1.5 0.2]\n",
      " [3.2 1.2 0.2]\n",
      " [3.5 1.3 0.2]\n",
      " [3.6 1.4 0.1]\n",
      " [3.  1.3 0.2]\n",
      " [3.4 1.5 0.2]\n",
      " [3.5 1.3 0.3]\n",
      " [2.3 1.3 0.3]\n",
      " [3.2 1.3 0.2]\n",
      " [3.5 1.6 0.6]\n",
      " [3.8 1.9 0.4]\n",
      " [3.  1.4 0.3]\n",
      " [3.8 1.6 0.2]\n",
      " [3.2 1.4 0.2]\n",
      " [3.7 1.5 0.2]\n",
      " [3.3 1.4 0.2]\n",
      " [3.2 4.7 1.4]\n",
      " [3.2 4.5 1.5]\n",
      " [3.1 4.9 1.5]\n",
      " [2.3 4.  1.3]\n",
      " [2.8 4.6 1.5]\n",
      " [2.8 4.5 1.3]\n",
      " [3.3 4.7 1.6]\n",
      " [2.4 3.3 1. ]\n",
      " [2.9 4.6 1.3]\n",
      " [2.7 3.9 1.4]\n",
      " [2.  3.5 1. ]\n",
      " [3.  4.2 1.5]\n",
      " [2.2 4.  1. ]\n",
      " [2.9 4.7 1.4]\n",
      " [2.9 3.6 1.3]\n",
      " [3.1 4.4 1.4]\n",
      " [3.  4.5 1.5]\n",
      " [2.7 4.1 1. ]\n",
      " [2.2 4.5 1.5]\n",
      " [2.5 3.9 1.1]\n",
      " [3.2 4.8 1.8]\n",
      " [2.8 4.  1.3]\n",
      " [2.5 4.9 1.5]\n",
      " [2.8 4.7 1.2]\n",
      " [2.9 4.3 1.3]\n",
      " [3.  4.4 1.4]\n",
      " [2.8 4.8 1.4]\n",
      " [3.  5.  1.7]\n",
      " [2.9 4.5 1.5]\n",
      " [2.6 3.5 1. ]\n",
      " [2.4 3.8 1.1]\n",
      " [2.4 3.7 1. ]\n",
      " [2.7 3.9 1.2]\n",
      " [2.7 5.1 1.6]\n",
      " [3.  4.5 1.5]\n",
      " [3.4 4.5 1.6]\n",
      " [3.1 4.7 1.5]\n",
      " [2.3 4.4 1.3]\n",
      " [3.  4.1 1.3]\n",
      " [2.5 4.  1.3]\n",
      " [2.6 4.4 1.2]\n",
      " [3.  4.6 1.4]\n",
      " [2.6 4.  1.2]\n",
      " [2.3 3.3 1. ]\n",
      " [2.7 4.2 1.3]\n",
      " [3.  4.2 1.2]\n",
      " [2.9 4.2 1.3]\n",
      " [2.9 4.3 1.3]\n",
      " [2.5 3.  1.1]\n",
      " [2.8 4.1 1.3]\n",
      " [3.3 6.  2.5]\n",
      " [2.7 5.1 1.9]\n",
      " [3.  5.9 2.1]\n",
      " [2.9 5.6 1.8]\n",
      " [3.  5.8 2.2]\n",
      " [3.  6.6 2.1]\n",
      " [2.5 4.5 1.7]\n",
      " [2.9 6.3 1.8]\n",
      " [2.5 5.8 1.8]\n",
      " [3.6 6.1 2.5]\n",
      " [3.2 5.1 2. ]\n",
      " [2.7 5.3 1.9]\n",
      " [3.  5.5 2.1]\n",
      " [2.5 5.  2. ]\n",
      " [2.8 5.1 2.4]\n",
      " [3.2 5.3 2.3]\n",
      " [3.  5.5 1.8]\n",
      " [3.8 6.7 2.2]\n",
      " [2.6 6.9 2.3]\n",
      " [2.2 5.  1.5]\n",
      " [3.2 5.7 2.3]\n",
      " [2.8 4.9 2. ]\n",
      " [2.8 6.7 2. ]\n",
      " [2.7 4.9 1.8]\n",
      " [3.3 5.7 2.1]\n",
      " [3.2 6.  1.8]\n",
      " [2.8 4.8 1.8]\n",
      " [3.  4.9 1.8]\n",
      " [2.8 5.6 2.1]\n",
      " [3.  5.8 1.6]\n",
      " [2.8 6.1 1.9]\n",
      " [3.8 6.4 2. ]\n",
      " [2.8 5.6 2.2]\n",
      " [2.8 5.1 1.5]\n",
      " [2.6 5.6 1.4]\n",
      " [3.  6.1 2.3]\n",
      " [3.4 5.6 2.4]\n",
      " [3.1 5.5 1.8]\n",
      " [3.  4.8 1.8]\n",
      " [3.1 5.4 2.1]\n",
      " [3.1 5.6 2.4]\n",
      " [3.1 5.1 2.3]\n",
      " [2.7 5.1 1.9]\n",
      " [3.2 5.9 2.3]\n",
      " [3.3 5.7 2.5]\n",
      " [3.  5.2 2.3]\n",
      " [2.5 5.  1.9]\n",
      " [3.  5.2 2. ]\n",
      " [3.4 5.4 2.3]\n",
      " [3.  5.1 1.8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "iris = load_iris()\n",
    "test_idx = [0,50,100]\n",
    "train_data = np.delete(iris.data, test_idx, axis=1)\n",
    "print(train_data.shape)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(597,)\n",
      "0th, 3.5\n",
      "1th, 1.4\n",
      "2th, 0.2\n",
      "3th, 4.9\n",
      "4th, 3.0\n",
      "5th, 1.4\n",
      "6th, 0.2\n",
      "7th, 4.7\n",
      "8th, 3.2\n",
      "9th, 1.3\n",
      "10th, 0.2\n",
      "11th, 4.6\n",
      "12th, 3.1\n",
      "13th, 1.5\n",
      "14th, 0.2\n",
      "15th, 5.0\n",
      "16th, 3.6\n",
      "17th, 1.4\n",
      "18th, 0.2\n",
      "19th, 5.4\n",
      "20th, 3.9\n",
      "21th, 1.7\n",
      "22th, 0.4\n",
      "23th, 4.6\n",
      "24th, 3.4\n",
      "25th, 1.4\n",
      "26th, 0.3\n",
      "27th, 5.0\n",
      "28th, 3.4\n",
      "29th, 1.5\n",
      "30th, 0.2\n",
      "31th, 4.4\n",
      "32th, 2.9\n",
      "33th, 1.4\n",
      "34th, 0.2\n",
      "35th, 4.9\n",
      "36th, 3.1\n",
      "37th, 1.5\n",
      "38th, 0.1\n",
      "39th, 5.4\n",
      "40th, 3.7\n",
      "41th, 1.5\n",
      "42th, 0.2\n",
      "43th, 4.8\n",
      "44th, 3.4\n",
      "45th, 1.6\n",
      "46th, 0.2\n",
      "47th, 4.8\n",
      "48th, 3.0\n",
      "49th, 0.1\n",
      "50th, 4.3\n",
      "51th, 3.0\n",
      "52th, 1.1\n",
      "53th, 0.1\n",
      "54th, 5.8\n",
      "55th, 4.0\n",
      "56th, 1.2\n",
      "57th, 0.2\n",
      "58th, 5.7\n",
      "59th, 4.4\n",
      "60th, 1.5\n",
      "61th, 0.4\n",
      "62th, 5.4\n",
      "63th, 3.9\n",
      "64th, 1.3\n",
      "65th, 0.4\n",
      "66th, 5.1\n",
      "67th, 3.5\n",
      "68th, 1.4\n",
      "69th, 0.3\n",
      "70th, 5.7\n",
      "71th, 3.8\n",
      "72th, 1.7\n",
      "73th, 0.3\n",
      "74th, 5.1\n",
      "75th, 3.8\n",
      "76th, 1.5\n",
      "77th, 0.3\n",
      "78th, 5.4\n",
      "79th, 3.4\n",
      "80th, 1.7\n",
      "81th, 0.2\n",
      "82th, 5.1\n",
      "83th, 3.7\n",
      "84th, 1.5\n",
      "85th, 0.4\n",
      "86th, 4.6\n",
      "87th, 3.6\n",
      "88th, 1.0\n",
      "89th, 0.2\n",
      "90th, 5.1\n",
      "91th, 3.3\n",
      "92th, 1.7\n",
      "93th, 0.5\n",
      "94th, 4.8\n",
      "95th, 3.4\n",
      "96th, 1.9\n",
      "97th, 0.2\n",
      "98th, 3.0\n",
      "99th, 1.6\n",
      "100th, 0.2\n",
      "101th, 5.0\n",
      "102th, 3.4\n",
      "103th, 1.6\n",
      "104th, 0.4\n",
      "105th, 5.2\n",
      "106th, 3.5\n",
      "107th, 1.5\n",
      "108th, 0.2\n",
      "109th, 5.2\n",
      "110th, 3.4\n",
      "111th, 1.4\n",
      "112th, 0.2\n",
      "113th, 4.7\n",
      "114th, 3.2\n",
      "115th, 1.6\n",
      "116th, 0.2\n",
      "117th, 4.8\n",
      "118th, 3.1\n",
      "119th, 1.6\n",
      "120th, 0.2\n",
      "121th, 5.4\n",
      "122th, 3.4\n",
      "123th, 1.5\n",
      "124th, 0.4\n",
      "125th, 5.2\n",
      "126th, 4.1\n",
      "127th, 1.5\n",
      "128th, 0.1\n",
      "129th, 5.5\n",
      "130th, 4.2\n",
      "131th, 1.4\n",
      "132th, 0.2\n",
      "133th, 4.9\n",
      "134th, 3.1\n",
      "135th, 1.5\n",
      "136th, 0.2\n",
      "137th, 5.0\n",
      "138th, 3.2\n",
      "139th, 1.2\n",
      "140th, 0.2\n",
      "141th, 5.5\n",
      "142th, 3.5\n",
      "143th, 1.3\n",
      "144th, 0.2\n",
      "145th, 4.9\n",
      "146th, 3.6\n",
      "147th, 1.4\n",
      "148th, 0.1\n",
      "149th, 4.4\n",
      "150th, 3.0\n",
      "151th, 1.3\n",
      "152th, 0.2\n",
      "153th, 5.1\n",
      "154th, 3.4\n",
      "155th, 1.5\n",
      "156th, 0.2\n",
      "157th, 5.0\n",
      "158th, 3.5\n",
      "159th, 1.3\n",
      "160th, 0.3\n",
      "161th, 4.5\n",
      "162th, 2.3\n",
      "163th, 1.3\n",
      "164th, 0.3\n",
      "165th, 4.4\n",
      "166th, 3.2\n",
      "167th, 1.3\n",
      "168th, 0.2\n",
      "169th, 5.0\n",
      "170th, 3.5\n",
      "171th, 1.6\n",
      "172th, 0.6\n",
      "173th, 5.1\n",
      "174th, 3.8\n",
      "175th, 1.9\n",
      "176th, 0.4\n",
      "177th, 4.8\n",
      "178th, 3.0\n",
      "179th, 1.4\n",
      "180th, 0.3\n",
      "181th, 5.1\n",
      "182th, 3.8\n",
      "183th, 1.6\n",
      "184th, 0.2\n",
      "185th, 4.6\n",
      "186th, 3.2\n",
      "187th, 1.4\n",
      "188th, 0.2\n",
      "189th, 5.3\n",
      "190th, 3.7\n",
      "191th, 1.5\n",
      "192th, 0.2\n",
      "193th, 5.0\n",
      "194th, 3.3\n",
      "195th, 1.4\n",
      "196th, 0.2\n",
      "197th, 7.0\n",
      "198th, 3.2\n",
      "199th, 4.7\n",
      "200th, 1.4\n",
      "201th, 6.4\n",
      "202th, 3.2\n",
      "203th, 4.5\n",
      "204th, 1.5\n",
      "205th, 6.9\n",
      "206th, 3.1\n",
      "207th, 4.9\n",
      "208th, 1.5\n",
      "209th, 5.5\n",
      "210th, 2.3\n",
      "211th, 4.0\n",
      "212th, 1.3\n",
      "213th, 6.5\n",
      "214th, 2.8\n",
      "215th, 4.6\n",
      "216th, 1.5\n",
      "217th, 5.7\n",
      "218th, 2.8\n",
      "219th, 4.5\n",
      "220th, 1.3\n",
      "221th, 6.3\n",
      "222th, 3.3\n",
      "223th, 4.7\n",
      "224th, 1.6\n",
      "225th, 4.9\n",
      "226th, 2.4\n",
      "227th, 3.3\n",
      "228th, 1.0\n",
      "229th, 6.6\n",
      "230th, 2.9\n",
      "231th, 4.6\n",
      "232th, 1.3\n",
      "233th, 5.2\n",
      "234th, 2.7\n",
      "235th, 3.9\n",
      "236th, 1.4\n",
      "237th, 5.0\n",
      "238th, 2.0\n",
      "239th, 3.5\n",
      "240th, 1.0\n",
      "241th, 5.9\n",
      "242th, 3.0\n",
      "243th, 4.2\n",
      "244th, 1.5\n",
      "245th, 6.0\n",
      "246th, 2.2\n",
      "247th, 4.0\n",
      "248th, 1.0\n",
      "249th, 6.1\n",
      "250th, 2.9\n",
      "251th, 4.7\n",
      "252th, 1.4\n",
      "253th, 5.6\n",
      "254th, 2.9\n",
      "255th, 3.6\n",
      "256th, 1.3\n",
      "257th, 6.7\n",
      "258th, 3.1\n",
      "259th, 4.4\n",
      "260th, 1.4\n",
      "261th, 5.6\n",
      "262th, 3.0\n",
      "263th, 4.5\n",
      "264th, 1.5\n",
      "265th, 5.8\n",
      "266th, 2.7\n",
      "267th, 4.1\n",
      "268th, 1.0\n",
      "269th, 6.2\n",
      "270th, 2.2\n",
      "271th, 4.5\n",
      "272th, 1.5\n",
      "273th, 5.6\n",
      "274th, 2.5\n",
      "275th, 3.9\n",
      "276th, 1.1\n",
      "277th, 5.9\n",
      "278th, 3.2\n",
      "279th, 4.8\n",
      "280th, 1.8\n",
      "281th, 6.1\n",
      "282th, 2.8\n",
      "283th, 4.0\n",
      "284th, 1.3\n",
      "285th, 6.3\n",
      "286th, 2.5\n",
      "287th, 4.9\n",
      "288th, 1.5\n",
      "289th, 6.1\n",
      "290th, 2.8\n",
      "291th, 4.7\n",
      "292th, 1.2\n",
      "293th, 6.4\n",
      "294th, 2.9\n",
      "295th, 4.3\n",
      "296th, 1.3\n",
      "297th, 6.6\n",
      "298th, 3.0\n",
      "299th, 4.4\n",
      "300th, 1.4\n",
      "301th, 6.8\n",
      "302th, 2.8\n",
      "303th, 4.8\n",
      "304th, 1.4\n",
      "305th, 6.7\n",
      "306th, 3.0\n",
      "307th, 5.0\n",
      "308th, 1.7\n",
      "309th, 6.0\n",
      "310th, 2.9\n",
      "311th, 4.5\n",
      "312th, 1.5\n",
      "313th, 5.7\n",
      "314th, 2.6\n",
      "315th, 3.5\n",
      "316th, 1.0\n",
      "317th, 5.5\n",
      "318th, 2.4\n",
      "319th, 3.8\n",
      "320th, 1.1\n",
      "321th, 5.5\n",
      "322th, 2.4\n",
      "323th, 3.7\n",
      "324th, 1.0\n",
      "325th, 5.8\n",
      "326th, 2.7\n",
      "327th, 3.9\n",
      "328th, 1.2\n",
      "329th, 6.0\n",
      "330th, 2.7\n",
      "331th, 5.1\n",
      "332th, 1.6\n",
      "333th, 5.4\n",
      "334th, 3.0\n",
      "335th, 4.5\n",
      "336th, 1.5\n",
      "337th, 6.0\n",
      "338th, 3.4\n",
      "339th, 4.5\n",
      "340th, 1.6\n",
      "341th, 6.7\n",
      "342th, 3.1\n",
      "343th, 4.7\n",
      "344th, 1.5\n",
      "345th, 6.3\n",
      "346th, 2.3\n",
      "347th, 4.4\n",
      "348th, 1.3\n",
      "349th, 5.6\n",
      "350th, 3.0\n",
      "351th, 4.1\n",
      "352th, 1.3\n",
      "353th, 5.5\n",
      "354th, 2.5\n",
      "355th, 4.0\n",
      "356th, 1.3\n",
      "357th, 5.5\n",
      "358th, 2.6\n",
      "359th, 4.4\n",
      "360th, 1.2\n",
      "361th, 6.1\n",
      "362th, 3.0\n",
      "363th, 4.6\n",
      "364th, 1.4\n",
      "365th, 5.8\n",
      "366th, 2.6\n",
      "367th, 4.0\n",
      "368th, 1.2\n",
      "369th, 5.0\n",
      "370th, 2.3\n",
      "371th, 3.3\n",
      "372th, 1.0\n",
      "373th, 5.6\n",
      "374th, 2.7\n",
      "375th, 4.2\n",
      "376th, 1.3\n",
      "377th, 5.7\n",
      "378th, 3.0\n",
      "379th, 4.2\n",
      "380th, 1.2\n",
      "381th, 5.7\n",
      "382th, 2.9\n",
      "383th, 4.2\n",
      "384th, 1.3\n",
      "385th, 6.2\n",
      "386th, 2.9\n",
      "387th, 4.3\n",
      "388th, 1.3\n",
      "389th, 5.1\n",
      "390th, 2.5\n",
      "391th, 3.0\n",
      "392th, 1.1\n",
      "393th, 5.7\n",
      "394th, 2.8\n",
      "395th, 4.1\n",
      "396th, 1.3\n",
      "397th, 6.3\n",
      "398th, 3.3\n",
      "399th, 6.0\n",
      "400th, 2.5\n",
      "401th, 5.8\n",
      "402th, 2.7\n",
      "403th, 5.1\n",
      "404th, 1.9\n",
      "405th, 7.1\n",
      "406th, 3.0\n",
      "407th, 5.9\n",
      "408th, 2.1\n",
      "409th, 6.3\n",
      "410th, 2.9\n",
      "411th, 5.6\n",
      "412th, 1.8\n",
      "413th, 6.5\n",
      "414th, 3.0\n",
      "415th, 5.8\n",
      "416th, 2.2\n",
      "417th, 7.6\n",
      "418th, 3.0\n",
      "419th, 6.6\n",
      "420th, 2.1\n",
      "421th, 4.9\n",
      "422th, 2.5\n",
      "423th, 4.5\n",
      "424th, 1.7\n",
      "425th, 7.3\n",
      "426th, 2.9\n",
      "427th, 6.3\n",
      "428th, 1.8\n",
      "429th, 6.7\n",
      "430th, 2.5\n",
      "431th, 5.8\n",
      "432th, 1.8\n",
      "433th, 7.2\n",
      "434th, 3.6\n",
      "435th, 6.1\n",
      "436th, 2.5\n",
      "437th, 6.5\n",
      "438th, 3.2\n",
      "439th, 5.1\n",
      "440th, 2.0\n",
      "441th, 6.4\n",
      "442th, 2.7\n",
      "443th, 5.3\n",
      "444th, 1.9\n",
      "445th, 6.8\n",
      "446th, 3.0\n",
      "447th, 5.5\n",
      "448th, 2.1\n",
      "449th, 5.7\n",
      "450th, 2.5\n",
      "451th, 5.0\n",
      "452th, 2.0\n",
      "453th, 5.8\n",
      "454th, 2.8\n",
      "455th, 5.1\n",
      "456th, 2.4\n",
      "457th, 6.4\n",
      "458th, 3.2\n",
      "459th, 5.3\n",
      "460th, 2.3\n",
      "461th, 6.5\n",
      "462th, 3.0\n",
      "463th, 5.5\n",
      "464th, 1.8\n",
      "465th, 7.7\n",
      "466th, 3.8\n",
      "467th, 6.7\n",
      "468th, 2.2\n",
      "469th, 7.7\n",
      "470th, 2.6\n",
      "471th, 6.9\n",
      "472th, 2.3\n",
      "473th, 6.0\n",
      "474th, 2.2\n",
      "475th, 5.0\n",
      "476th, 1.5\n",
      "477th, 6.9\n",
      "478th, 3.2\n",
      "479th, 5.7\n",
      "480th, 2.3\n",
      "481th, 5.6\n",
      "482th, 2.8\n",
      "483th, 4.9\n",
      "484th, 2.0\n",
      "485th, 7.7\n",
      "486th, 2.8\n",
      "487th, 6.7\n",
      "488th, 2.0\n",
      "489th, 6.3\n",
      "490th, 2.7\n",
      "491th, 4.9\n",
      "492th, 1.8\n",
      "493th, 6.7\n",
      "494th, 3.3\n",
      "495th, 5.7\n",
      "496th, 2.1\n",
      "497th, 7.2\n",
      "498th, 3.2\n",
      "499th, 6.0\n",
      "500th, 1.8\n",
      "501th, 6.2\n",
      "502th, 2.8\n",
      "503th, 4.8\n",
      "504th, 1.8\n",
      "505th, 6.1\n",
      "506th, 3.0\n",
      "507th, 4.9\n",
      "508th, 1.8\n",
      "509th, 6.4\n",
      "510th, 2.8\n",
      "511th, 5.6\n",
      "512th, 2.1\n",
      "513th, 7.2\n",
      "514th, 3.0\n",
      "515th, 5.8\n",
      "516th, 1.6\n",
      "517th, 7.4\n",
      "518th, 2.8\n",
      "519th, 6.1\n",
      "520th, 1.9\n",
      "521th, 7.9\n",
      "522th, 3.8\n",
      "523th, 6.4\n",
      "524th, 2.0\n",
      "525th, 6.4\n",
      "526th, 2.8\n",
      "527th, 5.6\n",
      "528th, 2.2\n",
      "529th, 6.3\n",
      "530th, 2.8\n",
      "531th, 5.1\n",
      "532th, 1.5\n",
      "533th, 6.1\n",
      "534th, 2.6\n",
      "535th, 5.6\n",
      "536th, 1.4\n",
      "537th, 7.7\n",
      "538th, 3.0\n",
      "539th, 6.1\n",
      "540th, 2.3\n",
      "541th, 6.3\n",
      "542th, 3.4\n",
      "543th, 5.6\n",
      "544th, 2.4\n",
      "545th, 6.4\n",
      "546th, 3.1\n",
      "547th, 5.5\n",
      "548th, 1.8\n",
      "549th, 6.0\n",
      "550th, 3.0\n",
      "551th, 4.8\n",
      "552th, 1.8\n",
      "553th, 6.9\n",
      "554th, 3.1\n",
      "555th, 5.4\n",
      "556th, 2.1\n",
      "557th, 6.7\n",
      "558th, 3.1\n",
      "559th, 5.6\n",
      "560th, 2.4\n",
      "561th, 6.9\n",
      "562th, 3.1\n",
      "563th, 5.1\n",
      "564th, 2.3\n",
      "565th, 5.8\n",
      "566th, 2.7\n",
      "567th, 5.1\n",
      "568th, 1.9\n",
      "569th, 6.8\n",
      "570th, 3.2\n",
      "571th, 5.9\n",
      "572th, 2.3\n",
      "573th, 6.7\n",
      "574th, 3.3\n",
      "575th, 5.7\n",
      "576th, 2.5\n",
      "577th, 6.7\n",
      "578th, 3.0\n",
      "579th, 5.2\n",
      "580th, 2.3\n",
      "581th, 6.3\n",
      "582th, 2.5\n",
      "583th, 5.0\n",
      "584th, 1.9\n",
      "585th, 6.5\n",
      "586th, 3.0\n",
      "587th, 5.2\n",
      "588th, 2.0\n",
      "589th, 6.2\n",
      "590th, 3.4\n",
      "591th, 5.4\n",
      "592th, 2.3\n",
      "593th, 5.9\n",
      "594th, 3.0\n",
      "595th, 5.1\n",
      "596th, 1.8\n"
     ]
    }
   ],
   "source": [
    "#p258\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree                           # 구분자 훈련을 위한 import\n",
    "iris = load_iris()\n",
    "test_idx = [0,50,100]           # 3종류의 꽃 리스트에서 가장 앞에 있는 1개씩의 데이터 3개!\n",
    "train_target = np.delete(iris.target, test_idx)     # 세 개의 요소들을 타깃변수에서 제거\n",
    "train_data = np.delete(iris.data, test_idx) # 세 개의 요소들을 데이터변수에서 제거\n",
    "print(train_data.shape)\n",
    "for i in range(len(train_data)):\n",
    "    print(\"%dth, %s\" % (i, train_data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1945bcb9888>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#p259\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "iris = load_iris()\n",
    "sepal = iris.data[:, 0:2]\n",
    "kind = iris.target\n",
    "plt.xlabel('Sepal Length')\n",
    "plt.ylabel('Sepal Width')\n",
    "plt.plot(sepal[kind==0][:,0], sepal[kind==0][:,1], \"ro\", label='Setosa')\n",
    "plt.plot(sepal[kind==1][:,0], sepal[kind==1][:,1], \"bo\", label='Versicolor')\n",
    "plt.plot(sepal[kind==2][:,0], sepal[kind==2][:,1], \"yo\", label='Virginica')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-56b84472d6c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#260\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdot_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"iris\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "#260\n",
    "import graphviz\n",
    "dot_data = tree.export_graphviz(clf, out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"iris\")\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                               feature_names=iris.feature_names,\n",
    "                               class_names=iris.target_names,\n",
    "                               filled=True, rounded=True,\n",
    "                               special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p261\n",
    "from sklearn.externals.six import StringIO\n",
    "import graphviz\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(clf, out_file=dot_data,\n",
    "                    feature_names=iris.feature_names,\n",
    "                    class_names=iris.target_names,\n",
    "                    filled=True, rounded=True,\n",
    "                    impurity=False)\n",
    "graph = graphviz.Source(dot_data.getvalue())\n",
    "graph.render(\"iris\", view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p262\n",
    "print(test_data[1], test_target[1])\n",
    "print(iris.feature_names, iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = range(6)\n",
    "print(list(y))\n",
    "print(train_test_split(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p263\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = range(6)\n",
    "print(list(y))\n",
    "print(train_test_split(y, test_size=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = np.arange(12).reshape((6, 2))\n",
    "y = range(6)\n",
    "print(X)\n",
    "print(list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = np.arange(12).reshape((6, 2))\n",
    "y = range(6)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측:\n",
      " [0 2 1 1 0 2 0 2 1 1 1 0 1 1 1 1 0 1 2 2 0 2 1 2 1 2 2 0 2 0 1 2 0 2 1 0 2\n",
      " 1 1 0 0 1 1 1 2 2 1 0 2 1 0 0 2 1 0 0 1 0 2 0 1 0 2 1 0 0 2 2 2 1 0 2 2 2\n",
      " 0]\n",
      "정답(y_test):\n",
      " [0 2 1 1 0 2 0 2 1 1 1 0 1 1 1 1 0 1 2 2 0 1 1 2 1 2 2 0 2 0 1 2 0 2 1 0 2\n",
      " 1 2 0 0 1 1 1 2 2 2 0 2 1 0 0 2 1 0 0 1 0 2 0 1 0 2 1 0 0 2 2 2 1 0 2 2 2\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "#p264\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5)\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print('예측:\\n', predictions)\n",
    "print('정답(y_test):\\n', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p265\n",
    "from sklearn.metrics import accuracy_score\n",
    "a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "b = [1, 2, 4, 4, 5, 6, 7, 8, 9, 10]\n",
    "print(accuracy_score(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최근접 이웃 탐색 모델\n",
    "### K-최근접이웃 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p266\n",
    "X = [[0], [1], [2], [3], [4], [5]]\n",
    "y = [0, 0, 0, 1, 1, 1]\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p267\n",
    "print(neigh.predict([[2.8]]))\n",
    "print(neigh.predict_proba([[2.8]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(neigh.predict([[2.3]]))\n",
    "print(neigh.predict_proba([[2.3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print('예측:\\n', predictions)\n",
    "print('정답(y_test):\\n', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p268\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나만의 분류자 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p269\n",
    "import random\n",
    "class myKNN():\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train      # X_train 데이터를 그대로 저장!\n",
    "        self.y_train = y_train      # y_train 데이터를 그대로 저장!\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for row in X_test:\n",
    "            label = random.choice(self.y_train)\n",
    "            predictions.append(label)\n",
    "        return predictions\n",
    "\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5)\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassfier 사용하지 않고\n",
    "clf = myKNN()                            # 나만의 분류자를 사용!\n",
    "clf.fit(X_train, y_train)\n",
    "preidctions = clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유클리디어 방식의 분류자 모델\n",
    "#### 요약 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p270\n",
    "import numpy as np\n",
    "def euc(p1, p2):\n",
    "    return np.sqrt(np.sum(np.power(p2-p1, 2)))\n",
    "p1 = np.array([1, 1])\n",
    "p2 = np.array([4, 4])\n",
    "euc(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "def euc(a, b) :\n",
    "    return distance.euclidean(a, b)\n",
    "p1 = np.array([1, 1])\n",
    "p2 = np.array([4, 4])\n",
    "euc(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "def euc(a, b) :\n",
    "    return distance.euclidean(a, b)\n",
    "p1 = np.array([1, 1, 3, 3])\n",
    "p2 = np.array([4, 4, 5, 5])\n",
    "euc(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p271\n",
    "from scipy.spatial import distance\n",
    "def euc(a,b) :\n",
    "    return distance.euclidean(a, b)\n",
    "class eucKNN():\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for row in X_test:\n",
    "            label = self.closest(row)\n",
    "            predictions.append(label)\n",
    "        return predictions\n",
    "    def closest(self, row):\n",
    "        best_dist = euc(row, self.X_train[0])\n",
    "        best_index = 0\n",
    "        for i in range(1, len(self.X_train)):\n",
    "            dist = euc(row, self.X_train[i])\n",
    "            if dist < best_dist:\n",
    "                best_dist = dist\n",
    "                best_index = 1\n",
    "        return self.y_train[best_index]\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5)\n",
    "clf = eucKNN()\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 서포트 벡터 머신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p272\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5)\n",
    "\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma=0.001, C=100.)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print(y_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [참고]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#p274\n",
    "import numpy as np\n",
    "points = 500\n",
    "vectors = []\n",
    "for i in range(points):\n",
    "    x1= np.random.normal(0.0, 0.5)\n",
    "    y1= x1 * 0.3 + 0.5 + np.random.normal(0.0, 0.05)\n",
    "    vectors.append([x1, y1])\n",
    "x_data = [v[0] for v in vectors]\n",
    "y_data = [v[1] for v in vectors]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x_data, y_data, 'bo', label='Data')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p275\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "points = 500\n",
    "vectors = []\n",
    "for i in range(points):\n",
    "    x1= np.random.normal(0.0, 0.5)\n",
    "    y1= x1 * 0.3 + 0.5 + np.random.normal(0.0, 0.05)\n",
    "    vectors.append([x1, y1])\n",
    "x_data = [v[0] for v in vectors]\n",
    "y_data = [v[1] for v in vectors]\n",
    "\n",
    "import tensorflow as tf\n",
    "a = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "y = a * x_data + b\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "%matplotlib inline\n",
    "for step in range(10):\n",
    "    sess.run(train)\n",
    "    plt.plot(x_data, y_data, 'bo')\n",
    "    plt.plot(x_data, sess.run(a) * x_data + sess.run(b))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
